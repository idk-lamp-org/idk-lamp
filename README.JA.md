# idk-lamp

AI が明示的に棄権できるようにするデザインの態度。

**idk-lamp** は意図的に最小限に設計されたデザインシグナルであり、AIシステムが  
明示的に **「わからない」** と言い — 決定を停止することを可能にします。

これは、自動判断が一時停止する必要がある境界を示し、  
責任が人間に戻ることを意味します。

これは製品ではありません。  
これは決定システムではありません。  

これは標識です。

---

## 定義

**idk-lamp** は **AI の棄権（abstention）** を表す小さな UI インジケーターです。

ランプが点灯しているとき、システムは失敗しているのではなく —  
不確実性、文脈の欠如、または責任の未定義により、  
明示的に **決定を拒否している** のです。

---

## 問題

現代の AI システムは常に答えを出すように最適化されています。

- 自然には棄権しない  
- 「わからない」とはほとんど言わない  
- 出力が確実性と誤解されることが多い  

その結果、責任の明確な引き継ぎなしに、  
決定が人間からシステムへと静かに移行する可能性があります。

---

## 原則

idk-lamp は一つの原則に基づいています：

> **責任が不明確な場合、AI は決定を停止しなければならない。**

確信を強要する代わりに、システムは  
判断が延期されたことを示す可視的な信号を発します。

説明なし。  
正当化なし。  
最適化なし。

ただ境界があるだけです。

---

## なぜ今なのか？

- AI システムがますます意思決定ループに組み込まれている  
- ハルシネーションと過信は未解決の問題のまま  
- 安全性が重視される領域と社会技術的領域が拡大している  
- 規制は説明責任と人間の監視を強調している  
- ほとんどのシステムには明示的な棄権メカニズムがまだない  

idk-lamp は *非決定* を可視化するために存在します。

詳細: [`docs/why-now.ja.md`](docs/why-now.ja.md)

---

## 概念マッピング（非規範的）

idk-lamp は規制や標準への **準拠を主張しません**。  
この表は、グローバルな AI ガバナンスの議論との **概念的な対応関係** を示しています。

| idk-lamp の概念              | 関連するグローバルフレームワーク                    |
|---------------------------|----------------------------------------|
| 棄権 / 拒否                  | NIST AI RMF – Measure / Manage         |
| 人間へのフォールバック            | EU AI Act – Human Oversight            |
| 適用範囲の境界                 | ISO/IEC 42001 – AI system scope        |
| 非決定の可視性                 | 説明責任と監査可能性の議論                        |

これは翻訳レイヤーであり — 認証の主張ではありません。

詳細: [`docs/mapping.ja.md`](docs/mapping.ja.md)

---

## 例（UI）

```html
<script src="https://idk-lamp.org/dist/idk-lamp.min.js"></script>

<idk-lamp state="idk"></idk-lamp>
```

---

## ライセンス

CC0 1.0 Universal
