# なぜ今なのか — idk-lamp が存在する理由

このドキュメントは、idk-lamp が **なぜ今必要なのか** を説明するものです。  
これは流行への反応ではなく、AI システムの利用構造が変化したことへの応答です。

---

## AI はもはや「支援」ではなく、実質的に *決定* を行っている

AI システムは意思決定ループに直接組み込まれるようになりました。  
**AI は事実上の意思決定者として振る舞う場面が増えています。**

単なる提案ではなく：

- ランク付けする
- フィルタする
- 承認・拒否する
- 行動をトリガーする

多くのシステムでは、**出力 = 決定** になっています。

---

## AI は自然には「わからない」と言わない

現代のAIは以下を最適化しています：

- 出力を生成すること
- 信頼度スコアを最大化すること
- ユーザー摩擦を最小化すること

つまり、**棄権に最適化されていない**。

その結果：

- 不確実性が隠蔽される
- 文脈不足が無視される
- 沈黙が自信と解釈される

---

## 過剰自信とキャリブレーション不良は未解決の問題

幻覚（hallucination）、過剰一般化、誤った自信は広く認識されています。

特にオープンエンドなタスクや文脈依存タスクでは、  
**過剰自信とキャリブレーション不良** は依然として未解決です。

それでも多くのシステムには、  
**非決定（棄権）を一級市民として扱う概念が存在しません。**

エラーは事後的に検出され、  
責任の移動は事前に可視化されません。

---

## 安全クリティカルかつ社会技術的な領域が拡大している

AI は次のような領域で使われています：

- 決定が不可逆的な領域
- 文脈がモデル更新より速く変化する領域
- 人間の責任を自動化できない領域

こうした領域では、  
**「決めるべきでない瞬間」を知ること** が決定と同じくらい重要です。

---

## ガバナンスはアカウンタビリティに集中しているが、UIシグナルは不足している

規制や標準は次を強調します：

- 人間の監督
- アカウンタビリティ
- 範囲定義
- リスク管理

しかし、それらが **インターフェース上でどう表現されるべきか**  
についてはほとんど触れられていません。

idk-lamp はこのギャップを、意図的にミニマルなシグナルで埋めます。

---

## なぜ棄権は可視化されるべきなのか

可視化されない場合：

- 非決定は失敗に見える
- 沈黙は自信に見える
- 責任移動が暗黙に起こる

可視化される場合：

- 棄権は意図的なものになる
- 責任のハンドオフが明示的になる
- システムの振る舞いが解釈可能になる

---

## idk-lamp は意図的に小さい

idk-lamp は AI 安全を解決しない。

次のことは行わない：

- リスク評価
- ポリシー強制
- 結果の決定

idk-lamp が可視化するのはただ一つ：

> **AI システムが「決めるのをやめた瞬間」。**

それだけでシステムの理解が変わる。

---

## まとめ

idk-lamp が存在する理由：

- AI は私たちが認める以上に決定している
- AI は止まるべき瞬間を知らない
- 責任移動が静かに起こる
- ガバナンスには UI プリミティブが欠けている

idk-lamp は **棄権の視覚プリミティブ** を導入する。  
それは現代のAIシステムに必要な **デザイン態度** である。
