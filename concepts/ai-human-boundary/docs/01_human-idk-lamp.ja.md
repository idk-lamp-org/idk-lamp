# 01_human-idk-lamp — 人間側の「分からないランプ」

この文書は、  
**人間にも idk-lamp（判断を閉じられないシグナル）が必要である**  
という考え方を整理したものです。

AI に idk-lamp が必要だったように、  
AI 時代の人間にも同じ構造が必要になります。

---

# 1. なぜ「人間側の idk-lamp」が必要なのか

AI と人が一緒に考えるとき、  
人間はしばしば次のような状況に置かれます。

- 判断材料はあるが、決めきれない  
- 不確実性が大きすぎる  
- 未来の影響が読めない  
- 責任の重さが大きい  
- 価値の選択が絡む  

しかし、人間はこれを **黙って抱え込んでしまう** ことが多い。

その結果、

- 無理に決断してしまう  
- AI の提案をそのまま採用してしまう  
- 本当は判断できないのに「できるふり」をしてしまう  

という問題が起きる。

これを防ぐために必要なのが、  
**人間側の idk-lamp** です。

---

# 2. 人間側の idk-lamp が示すもの

人間側の idk-lamp は、次の状態を示します。

- 今は判断できない  
- 今は決められない  
- 今は不確実性が大きすぎる  
- 今は責任を引き受けられない  
- 今は選択の価値を決められない  

これは弱さではなく、  
**意思決定の健全性を守るためのシグナル**です。

---

# 3. 人間同士では自然に共有される「不確実性」

人間同士の会話では、  
不確実性は“空気”として自然に共有されます。

- 相手の迷い  
- 相手の不安  
- 相手の責任感  
- 相手の賭けの感覚  
- 相手の価値観の揺れ  

これらは言葉にしなくても伝わる。

だから人間同士は、  
**不確実性を共有しながら意思決定できる**。

---

# 4. 人＋AI では不確実性が共有されない

AI は構造的に次のことができません。

- 一緒に悩む  
- 一緒に賭ける  
- 一緒に責任を持つ  
- 一緒に不安を抱える  
- 一緒に未来を想像する  

つまり、AI は **不確実性の共犯者になれない**。

そのため、人間が「分からない」と言わない限り、  
AI はその不確実性を認識できない。

---

# 5. 人間側の idk-lamp が果たす役割

人間側の idk-lamp は、次の役割を持ちます。

### ● ① 自分自身へのシグナル  
「今は決められない」という事実を  
自分で認識するためのメタ認知。

### ● ② AI へのシグナル  
AI に対して  
「判断を閉じる段階ではない」  
ことを伝える。

### ● ③ 周囲（人間）へのシグナル  
チームや関係者に  
「今は判断を保留すべき」  
という状態を共有する。

### ● ④ 責任の暴走を防ぐ  
判断を急がせる圧力から  
自分を守るための境界。

---

# 6. どんなときに「人間側の idk-lamp」を点灯すべきか

次のような場面では、  
積極的に idk-lamp を点灯すべきです。

- 判断の根拠が薄い  
- 未来の影響が大きい  
- 価値の選択が絡む  
- 自分の状態が不安定  
- 情報が足りない  
- 責任が重すぎる  
- AI の回答が滑らかすぎて不安  

特に最後の項目は重要です。

> AI の回答が整っているほど、  
> 人間は「不確実性が省略されている」ことを忘れやすい。

---

# 7. 人間側の idk-lamp の具体的な表現例

これはルールではなく、  
あくまで“表現の例”です。

- 「今は判断できません」  
- 「もう少し考える時間が必要です」  
- 「この不確実性は自分では扱えません」  
- 「これは価値の選択なので、すぐには決められません」  
- 「判断を保留します」  

重要なのは、  
**判断を止めることを恥じない** こと。

---

# 8. 人間側の idk-lamp と Decision Closure の関係

Decision Closure は  
**AI が判断を閉じてよいか** を決める構造。  
BOA では RCA / RP として実装に落とされます。

人間側の idk-lamp は  
**人間が判断を閉じてよいか** を決めるシグナル。

両者は次のように補完し合う。

AI：閉じてはいけない判断を閉じない（Decision Closure）
人：閉じられない判断を閉じない（human-idk-lamp）

コード

この二つが揃って初めて、  
AI と人の協働が健全になる。

---

# 9. まとめ（短い版）

- 人間にも「分からないランプ」が必要  
- 人間同士では自然に共有される不確実性は、AIとは共有されない  
- AIは不確実性の共犯者になれない  
- 判断できない状態を示すことは弱さではなく境界  
- 人間側の idk-lamp は、意思決定の健全性を守るための構造  
- Decision Closure と対になる存在  

---

# 10. 次に読むべき文書

- 02_uncertainty.ja.md（不確実性の扱い）  
- 03_action-layer.ja.md（行動レイヤーの3軸）  
- 04_relationship-with-decision-closure.ja.md（DCとの関係）
