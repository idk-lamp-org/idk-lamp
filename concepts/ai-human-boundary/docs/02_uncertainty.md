# 02_uncertainty â€” Handling Uncertainty

This document organizes
**"Uncertainty," which becomes most important when AI and humans think together**.

AI can "handle" uncertainty,
but it **cannot "share" uncertainty**.

This difference determines the boundary between AI and humans.

---

# 1. What is Uncertainty?

Uncertainty refers to the following states:

- Cannot read the future
- Results are not guaranteed
- Material for judgment is not complete
- Choice of value is involved
- Risk does not become zero

Human decision-making is
always conducted within this uncertainty.

---

# 2. Humans Can "Share Uncertainty"

In decision-making between humans,
the following "sharing" naturally exists:

- The other person is also hesitating
- The other person is also holding anxiety
- The other person is also feeling responsible
- The other person is also participating in the bet
- The other person also cannot read the future

In other words, humans can become **accomplices in uncertainty**.

Because of this "complicity,"
humans can support each other in uncertain choices.

---

# 3. AI Cannot "Become an Accomplice in Uncertainty"

AI structurally cannot do the following:

- Worry together
- Bet together
- Hold responsibility together
- Hold anxiety together
- Imagine the future together

AI can "calculate" uncertainty,
but it **cannot "hold it together"**.

Therefore, AI cannot step into the following areas:

- Pushing someone's back
- Encouraging a bet
- Giving courage
- Sharing the risk

These are all **territories unique to humans**.

---

# 4. AI's Answers "Omit Uncertainty"

AI's answers are smooth and polished,
but behind them, the following are not included:

- Hesitation
- Anxiety
- Betting
- Responsibility
- Values
- Fear of the future

In other words, AI's answers are presented in a **state where uncertainty has "dropped out"**.

This is not a defect,
but **a structural property of AI**.

---

# 5. What Happens When Uncertainty is Omitted?

When humans see AI's smooth answers,
they easily misunderstand as follows:

- "This must be certain"
- "If there is no hesitation, it must be correct"
- "If AI says so, it must be okay"

However, in reality,

> **AI merely omits uncertainty,
> and does not share the "weight" of that judgment.**

This gap
jeopardizes human decision-making.

---

# 6. Handling Uncertainty is the Human's Role

To handle uncertainty, the following elements are required:

- Courage
- Values
- Responsibility
- Intuition
- Experience
- Preparedness for the future

These are all **capabilities unique to humans**,
and not areas that AI can substitute.

That is precisely why,

> **Judgment choosing uncertainty is a judgment that should be closed by humans**
> and should not be closed by AI.

---

# 7. Uncertainty and "Human-side idk-lamp"

When uncertainty is large,
humans enter the following states:

- Cannot judge
- Cannot decide
- Scared of the future
- Heavy responsibility
- Insufficient information

What is needed to indicate this state is
the **Human-side idk-lamp**.

Just as AI has an idk-lamp,
humans also need to show the signal "judgment cannot be closed now"
to themselves and their surroundings.

---

# 8. Relationship Between Uncertainty and Decision Closure

Decision Closure is
a structure to decide **whether AI can close the judgment**.  
In BOA, it is realized in implementation as RCA / RP.

Judgments with large uncertainty
will inevitably collapse in one of the 5 steps of Decision Closure.

- Responsibility is dispersed
- Cannot cancel
- Social context arises
- Action chains

In other words,

> **Judgments with large uncertainty are judgments AI must not close**

This becomes the conclusion.

---

# 9. Summary (Short version)

- Uncertainty is the center of human decision-making
- Humans can share uncertainty with each other
- AI cannot become an accomplice in uncertainty
- AI's answers omit uncertainty
- Judgment choosing uncertainty is the human domain
- When uncertainty is large, the human-side idk-lamp is necessary
- Decision Closure is a structure to remove judgments with large uncertainty from AI

---

# 10. Documents to Read Next

- 03_action-layer.md (3 Axes of Action Layer)
- 04_relationship-with-decision-closure.md (Relationship with DC)
