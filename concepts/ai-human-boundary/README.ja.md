# ai-human-boundary

🌿 **AI と人が一緒に価値を選ぶための境界ガイド**

このリポジトリは、  
**AI → 人** ではなく  
**AI＋人 → 価値**  
という関係を前提に、

> 人が AI と付き合うときに、  
> 最低限「知っておくべき境界」

を整理・記録するためのものです。

---

## このリポジトリは何か

このリポジトリは、

- AI を賢く使う方法  
- AI に任せるための設計  
- AI の精度や性能の話  

を扱いません。

扱うのはただ一つです。

> **AIと一緒に考えるとき、  
> どこから先は人が引き受けるべきか**

---

## 前提：これは「設計」ではなく「ガイド」です

ここで書かれている内容は、

- ルールではありません  
- 実装仕様ではありません  
- 判断基準を強制するものでもありません  

これは、  
**AI時代に人が壊れないための理解のガイド**です。

---

## 1. AIは「不確実性を共有できない」

人間同士なら、自然に起きることがあります。

- 一緒に悩む  
- 一緒に賭ける  
- 一緒に不安を抱える  
- 一緒に責任を引き受ける  

AIは、これらを **構造的にできません**。

AIは不確実性を「扱う」ことはできても、  
**不確実性を一緒に引き受けることはできない**。

だから、

> 不確実な選択を後押しするのは、人間の役割です。

---

## 2. AIの回答は整っているが、不確実性が省略されている

AIの回答は、

- 滑らかで  
- 迷いがなく  
- もっともらしい  

しかし、その裏側には、

- 迷い  
- 不安  
- 賭け  
- リスク  
- 責任  

が **含まれていません**。

必要なときには、  
次の事実を思い出す必要があります。

> **AIは不確実性を省略する**

これは欠陥ではなく、性質です。

---

## 3. AIは「判断を閉じてよいか」を自分で決められない

AIは、自分の出力が

- 参考として使われるのか  
- 行動の根拠になるのか  
- 誰かの判断を代替してしまうのか  

を観測できません。

そのため、

- 責任が分散したら閉じられない  
- 取消できないなら閉じられない  
- 社会的文脈が立ち上がったら閉じられない  

といった条件を、  
**構造として持つ必要があります**。

この考え方は  
**Decision Closure（判断閉路構造）** として整理されています。  
BOA では RCA / RP として実装に落とされます。

---

## 4. 人間にも「分からないランプ」が必要

AIには idk-lamp という考え方があります。

しかし本当は、  
**人間にも必要**です。

- 今は判断できない  
- 今は決められない  
- 今は不確実性が大きすぎる  

これを、  
自分自身や周囲に伝えるためのシグナル。

> 人間が「分からない」と言えることは、  
> AI時代の重要なスキルです。

---

## 5. AIの提案は「行動の責任」を肩代わりしない

行動のレイヤーには、  
次の3つの軸しかありません。

- 知っている / 知らない  
- 提案のまま行動した / 人が判断した  
- 人間自身もギブアップした  

つまり、

> **行動の責任は常に人間にあります**

AIは行動の共犯者にはなれません。

---

## 6. AIは「人間の価値」を知らない

AIは価値判断を持ちません。

- 何を大切にするか  
- 何を失いたくないか  
- どんな未来を選ぶか  
- どんなリスクを許容するか  

これらは、  
**人間固有の領域**です。

AIは価値を推測することはできても、  
**共有することはできません**。

---

## 7. AIは補助であって、代替ではない

AIは、

- 判断材料を提供できる  
- 視点を増やせる  
- 思考を整理できる  

しかし、

- 背中を押さない  
- 賭けに参加しない  
- 責任を持たない  

だからこそ、

> **最終判断は人間が閉じるべきです**

それは責任ではなく、  
**価値を選ぶ行為**だからです。

---

## まとめ（短い版）

AIと付き合うために、  
人が最低限知っておくべきことは、これだけです。

- AIは不確実性を共有できない  
- AIの回答は不確実性が省略されている  
- AIは判断を閉じてよいかを自分で決められない  
- 人間にも「分からないランプ」が必要  
- 行動の責任は常に人間にある  
- 価値判断は人間の領域  
- AIは補助であって代替ではない  

---

## このリポジトリの位置づけ

- Decision Closure：  
  AIが判断を閉じてよいかを決める構造

- ai-human-boundary：  
  人が AI と一緒に価値を選ぶためのガイド

このリポジトリは、  
**構造の外側で、人がどう立つか**を扱います。

---

## ステータス

- 状態：Draft / Living Document  
- 目的：忘れないための整理  
- 実装・UI：対象外  

---

## 最後に

AIが賢くなるほど、  
人が「決めなくてよい理由」は増えていきます。

それでも、

> **何を選ぶかは、人が決める**

この境界を忘れないために、  
このリポジトリは存在します。

---

## Context

このプロジェクトは、AIが判断を止め、
人間の責任へと委ねるべき境界を可視化するための
実践的なシグナルとして設計されています。

- idk-lamp（公式サイト）  
  https://idk-lamp.org/ja

この取り組みは、AI支援システムにおける
設計・責任・境界のあり方を探究する
設計思想 VCDesign から生まれました。

- VCDesign  
  https://vcdesign.org/ja

本リポジトリは単体でも利用・理解できます。  
事前知識は必要ありません。
